\section{Related Work}\label{sec:relatedWork}

Strong Branching is an efficient branching strategy in terms of the number of nodes generated but is costly in terms of time.
To mitigate the time cost disadvantage of the Strong Branching strategy, researchers have focused on developing strategies that can make Strong Branching-like decisions more quickly and efficiently.
One group of researchers aimed to leverage machine learning techniques to learn a function that would mimic the Strong Branching strategy.


\subsection{ExtraTrees Based Imitation of Strong Branching}\label{subsec:extratrees-based-imitation-of-strong-branching}
One of the pioneering studies in this field belongs to Alvarez et al.~\cite{alvarezMachineLearningBasedApproximation2017}.
In this study, Alvarez et al.~\cite{alvarezMachineLearningBasedApproximation2017} attempted to mimic the Strong Branching strategy by using a machine learning algorithm called ExtraTrees~\cite{geurtsExtremelyRandomizedTrees2006}.
The method used in this study consists of three steps.


In first step, randomly generated set covering (SC), multi knapsack (MKN), bin packing (BP), and equality (EQ) problems were solved using the Strong Branching strategy.
In addition to the Strong Branching scores calculated for each variable at each node, static problem features such as cost coefficient of variable $i$, dynamic problem features such as the fractionality of variable $i$ at the current solution and dynamic optimization features such as the number of times variable $i$ has been chosen as branching variable were also recorded for use during the training phase.
Detailed description of features can be seen in Appendix A Table 0.1. % burası revize edilecek


In second step, a function to mimic Strong Branching was learned using the ExtraTrees machine learning algorithm with $10^5$ training examples.
Alvarez et al.~\cite{alvarezMachineLearningBasedApproximation2017} approached the problem as a regression problem.
The recorded features were utilized as inputs to learn a weight vector for calculating the Strong Branching score for each branching candidate variable, in a manner similar to the Strong Branching strategy.
It can be stated that the learning process occurs offline.


In third step, the learned heuristic and other branching strategies (Random Branching, Most Infeasible Branching (MIB), Nonchimerical Branching (NCB), Full Strong Branching (FSB), and Reliability Branching (RB) were tested on two different datasets: randomly generated problems and standard benchmark problems from MIPLIB.
At this stage, two types of experiments were performed.
The first involved terminating the optimization process early, based on a predefined limit on either the number of nodes(a limit of $10^5$ nodes) explored or the computation time (a limit of 10 minutes) elapsed.
The second set of experiments allowed the problems to be solved to optimality, regardless of the time or node required.


An analysis of the experimental results, where MIPLIB problems were solved using CPLEX under node and time limits, reveals that the proposed branching strategy performs comparably to strong branching in both scenarios.
However, the performance of the learned branching strategy remains slightly inferior to that achieved with Reliability Branching (RB).
The closed gap (“Cl. Gap”) in Table~\ref{tab:alvarez-results} is defined as the ratio of the difference between the current dual bound and the objective value of the initial LP relaxation to the difference between the optimal objective value and the objective value of the initial LP relaxation.
A value close to 1 indicates that the optimization process is nearing its final stages.

\input{tables/alvarez_results}


When we examine the experimental results in which MIPLIB problems were solved by CPLEX until optimality, as can be seen in Table~\ref{tab:alvarez-results-2}, it is observed that the learned function is the strategy that produces the fastest solutions when cuts and heuristics are used by CPLEX.
It was observed that the learned function solved the problems with fewer nodes compared to the Random and MIB strategies.
However, in terms of node count, the learned function is less effective than the RB and NCB strategies.
When cuts and heuristics are not used by CPLEX learned function seems to be non-efficient in terms of node count and time.

\input{tables/alvarez_results_2}


\subsection{ExtraTrees Based Imitation of Strong Branching}
Another study in this field was conducted by Khalil et al~\cite{khalilLearningBranchMixed2016}.
In this study, the researchers attempted to mimic the Strong Branching strategy using the svmRank machine learning algorithm.
This study consists of three steps.


In first step, unlike the study by Alvarez et al.~\cite{alvarezMachineLearningBasedApproximation2017}, in this research, training and testing were conducted on the same problem instance.
It can be stated that the learning process occurs online.
Branching was performed using Strong Branching for the first $\Theta$ nodes of each problem.
Each variable was assigned a label based on the Strong Branching score.
The following formula was used for label assignment:

\[ y_i^n = \begin{cases}
      1 & S_i^n\geq (1-\alpha)S_*^n \\
      0 & otherwise
   \end{cases}
\]

where $S_*^n$ is maximum SB score and the parameter $\alpha$ $\in$ [0, 1] represents the fraction of the maximum Strong Branching ($S_*^n$) that a variable must achieve to be assigned a label of '1'.
At each node, the assigned labels and the static features such as objective function coefficients and dynamic features such as the fractionality of variable i at the current solution were recorded as training data.
Detailed description of features can be seen in Appendix A Table 0.2. % burası revize edilecek


In second step, unlike Alvarez et al.~\cite{alvarezMachineLearningBasedApproximation2017}, Khalil et al.~\cite{khalilLearningBranchMixed2016} approached the problem as a ranking problem.
Instead of predicting the Strong Branching score as Alvarez et al.~\cite{alvarezMachineLearningBasedApproximation2017} did, the researchers focused on ranking the variables among themselves in a manner similar to Strong Branching.
According to the researchers, the exact Strong Branching score is not important; what matters is that the variables are ranked among themselves in the way Strong Branching would.
At this stage, a linear function ($f$) was learned using the svmRank~\cite{joachimsTrainingLinearSVMs2006} machine learning algorithm and Pairwise loss~\cite{joachimsOptimizingSearchEngines}:

\[
f: \mathbb{R}^p \rightarrow \mathbb{R}, \quad
f\left(\Phi(x_i, N_n)\right) = \mathbf{w}^T \Phi(x_i, N_n), \quad
\]

\[
\hat{y}_i^n = f\left(\Phi(x_i, N_n)\right),
\]

\[
\mathbf{w}^* = \arg\min_{\mathbf{w} \in \mathbb{R}^p}
\sum_{N_n \in N} \ell(\mathbf{y}^n, \hat{\mathbf{y}}^n)
+ \lambda \| \mathbf{w} \|_2^2
\]

where $\Phi(x_i, N_n)$ denotes variable $x_i$ at node $N_n$ with $p$ features, $\mathbf{w}^*$ denotes learned weight vector, $\ell$ denotes the loss function (Pairwise loss), $\lambda$ denotes regularization parameter that helps to avoid overfitting, $\hat{\mathbf{y}}^n$ denotes vector of values resulting from applying $f$ to every fractional variable in $N_n$, $\mathbf{y}^n$ denotes the true label of every fractional variable in $N_n$.


In third step, the learned weight vector was used for branching instead of Strong Branching.
The feature vectors of the variables were multiplied by the learned weight vector to calculate a score for each variable.
The variable with the highest score was selected for branching.


In the experimental phase, the developed method (SB+ML) was tested on MIPLIB2010 problems.
The results were compared with CPLEX's default branching strategy (CPLEX-D), Strong Branching (SB), Pseudocost Branching (PC), and the SB + PC strategy. SB+PC is a hybrid approach that uses SB for the first $\Theta$ = 500 nodes, and PC afterward.
Experiments were conducted on a total of 523 problems.
Problems solved by CPLEX-D with fewer than 50,000 nodes were classified as Easy, those solved with more than 50,000 but fewer than 500,000 nodes as Medium, and those solved with more than 500,000 nodes as Hard.
The experimental results are summarized in the Table~\ref{tab:khalil-results}:

\input{tables/khalil_results}


The researchers analyzed the experimental results from three perspectives: the number of unsolved problems, the total number of nodes, and the total solution time.
Since the researchers claimed that the developed method is better at selecting branching variables, the primary metric they focused on was the total number of nodes.
As can be seen from the table above, the developed method (SB+ML) is more successful in terms of the total number of nodes compared to PC and SB+PC.
When considering all the problems, it was observed that the developed method reduced the solution time compared to the Strong Branching strategy, while increasing the number of nodes.


\subsection{GCNN Based Imitation of Strong Branching}\label{subsec:gcnn-based-imitation-of-strong-branching}
In another study in this field, Gasse et al.~\cite{gasseExactCombinatorialOptimization2019} attempted to mimic the Strong Branching strategy using a Graph Convolutional Neural Network (GCNN).
In this study, the researchers used the bipartite graph representation of MILP problems, enabling the use of GCNN in solving MILP problems.
This study consists of three steps.


In first step, 100,000 branching examples were collected from 10,000 randomly generated MILP problems (Set Covering Problems, Combinatorial Auction Problems,Capacitated Facility Location Problems, Maximum Independent Set Problems).
For each branching example, the Strong Branching scores calculated for the variables and variable features such as objective coefficient, constraint features such as dual solution value, edge features such as constraint coefficient were collected.
Detailed description of features can be seen in Appendix A Table 0.3. % burası revize edilecek


In second step, unlike Alvarez et al.~\cite{alvarezMachineLearningBasedApproximation2017} and Khalil et al.~\cite{khalilLearningBranchMixed2016}, Gasse et al.~\cite{gasseExactCombinatorialOptimization2019} approached the problem as a classification problem.
They attempted to learn how to select the variable to be used in branching with a Graph Neural Network, mimicking the approach of the Strong Branching strategy.
The GNN architecture used here essentially consists of three components as can be seen in Figure~\ref{fig:gcnn}.

\begin{figure*}[htb!]
    \centering
    \includegraphics[width=1\textwidth]{figures/GCNN}
    \caption{GNN architecture developed by Gasse et al.~\cite{gasseExactCombinatorialOptimization2019}.}
    \label{fig:gcnn}
\end{figure*}


\begin{itemize}
  \item Preprocessing Layers: At this stage, the constraint features and variable features are transformed into 64-dimensional embeddings using a fully connected 2-layer MLP with layer normalization~\cite{baLayerNormalization2016} and ReLU activation function.
  Layer normalization is applied to the edge features.
  \item GCNN Layers: The variable, constraint, and edge features undergo convolution operations twice.
  The researchers developed a custom convolution operator called Bipartite Graph Convolution for this process, the details of which are shown in Figure~\ref{fig:convolution}.
  \item Fully Connected MLP: At this stage, the variable embeddings, which have undergone two convolution operations, are passed through a 2-layer MLP.
  A ReLU activation function is used in the first layer, A SoftMax activation function is used in the second layer.
  As a result of this process, the 64-dimensional embeddings for each variable are converted into a single-dimensional score.
\end{itemize}


The developed GNN architecture was trained on 100,000 branching examples using the Adam Optimizer~\cite{kingmaAdamMethodStochastic2017} and Cross Entropy Loss.

\begin{figure*}[htb!]
    \centering
    \includegraphics[width=1\textwidth]{figures/Convolution}
    \caption{Bipartite Graph Convolution Layer developed by Gasse et al.~\cite{gasseExactCombinatorialOptimization2019}.}
    \label{fig:convolution}
\end{figure*}


In third step, Gasse et al.~\cite{gasseExactCombinatorialOptimization2019}'s developed model was compared with Full Strong Branching (FSB), Reliability Pseudocost Branching (RPB), the ExtraTrees method developed by Alvarez et al.~\cite{alvarezMachineLearningBasedApproximation2017} (TREES), LambdaMART method developed by Hansknecht et al.~\cite{hansknechtCutsPrimalHeuristics2018a} (LMART) and the svmRank method developed by Khalil et al.~\cite{khalilLearningBranchMixed2016} (SVMRANK) using 100 easy, 100 medium, 100 hard problems.
Problem parameters can be seen in Table~\ref{tab:gasse-benchmark-problems}.

\input{tables/gasse_benchmark_problems}


The performance of different branching methods was evaluated based on the number of nodes required to solve instances and the overall solving time, which includes the computational cost of branching policies such as feature extraction and inference.
As can be seen from the Table~\ref{tab:gasse-results}, The GCNN model demonstrated superior performance overall, particularly excelling in generalizing to larger instances and outperforming SCIP's default RPB branching rule in nearly all configurations, especially on medium and hard instances of set cover and combinatorial auction problems.
However, it faced challenges with the maximum independent set problem, showing high variability in both runtime and node count.


Although the FSB expert brancher produced small search trees, it was not competitive in runtime.
The study marks the first comparison of a machine learning-based method with a comprehensive MILP solver, highlighting GCNN's potential as a promising addition to MILP solvers for accelerating mixed-integer linear programming tasks.
These findings suggest that tighter integration of GCNN within a MILP solver could unlock further improvements.

\input{tables/gasse_results}

\subsection{The Distinction of Study from Previous Works}
In this study, unlike the approaches of Alvarez et al.~\cite{alvarezMachineLearningBasedApproximation2017} and Khalil et al.~\cite{khalilLearningBranchMixed2016}, the problem is formulated as a classification task.
According to the Universal Approximation Theorem~\cite{luUniversalApproximationTheorem2020}, it is theoretically possible to approximate any function given a sufficient number of neurons.
To leverage the high learning capacity of neural networks, this study employs Graph Neural Networks (GNNs) as the machine learning algorithm, as was done in the study by Gasse et al.~\cite{gasseExactCombinatorialOptimization2019}.
Gasse et al.~\cite{gasseExactCombinatorialOptimization2019} demonstrated in their research that the Graph Neural Network algorithm achieves superior performance compared to alternative methods such as Alvarez et al.~\cite{alvarezMachineLearningBasedApproximation2017}’s ExtraTrees algorithm and Khalil et al.~\cite{khalilLearningBranchMixed2016}’s SVMRank algorithm.


The key point of divergence between this study and the work of Gasse et al.~\cite{gasseExactCombinatorialOptimization2019} lies in the design of the convolutional layers utilized in the GNN architecture.
In the Graph Convolutional Neural Network (GCNN) architecture, all neighboring nodes are treated with equal significance when aggregating information for a given node.
However, this assumption often does not hold true for most real-world problems, where the importance of neighboring nodes varies.
To address this limitation, the Graph Attention Network (GAT) architecture introduces an attention mechanism that assigns varying levels of importance to neighboring nodes.
By learning adaptive weights for these neighbors, GAT provides a more nuanced representation of node relationships.


This ability to differentiate the significance of neighbors makes GAT a promising candidate for solving combinatorial optimization problems more effectively than GCNN.
This modification is aimed at further enhancing the model's ability to effectively address the underlying problem, highlighting the novelty of the proposed approach.